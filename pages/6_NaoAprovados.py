import streamlit as st
import pandas as pd
from src.db_snowflake import apply_common_filters, build_user_options, get_session, load_user_display_map
from src.auth import current_user, require_roles
from src.utils import extrair_valores, gerar_sinonimo 
from src.variables import FQN_MAIN, FQN_COR, FQN_APR

st.title("N√£o Aprovados")

require_roles("ADMIN", "OPERACIONAL")
user = current_user()
session = get_session()


ORDER_CORRECOES = [
    "ID","GRUPO","CATEGORIA","SEGMENTO","FAMILIA","SUBFAMILIA",
    "TIPO_CODIGO","CODIGO_PRODUTO","INSUMO","ITEM","DESCRICAO","ESPECIFICACAO",
    "MARCA","QTD_EMB_PRODUTO", "EMB_PRODUTO", "QTD_MED", "UN_MED", "QTD_EMB_COMERCIAL", "EMB_COMERCIAL",
    "SINONIMO","PALAVRA_CHAVE","REFERENCIA",
    "DATA_CADASTRO","USUARIO_CADASTRO",
    "DATA_REPROVACAO","USUARIO_REPROVACAO",      # novos
    "MOTIVO",
    "DATA_ATUALIZACAO","USUARIO_ATUALIZACAO",
]

EDITABLE_COR_COLS = [
    "GRUPO","CATEGORIA","SEGMENTO","FAMILIA","SUBFAMILIA","TIPO_CODIGO","CODIGO_PRODUTO",
    "INSUMO","ITEM","DESCRICAO","ESPECIFICACAO","QTD_EMB_PRODUTO", "EMB_PRODUTO", 
    "QTD_MED", "UN_MED", "QTD_EMB_COMERCIAL", "EMB_COMERCIAL"
    ,"SINONIMO","PALAVRA_CHAVE","REFERENCIA"
]

def reorder(df: pd.DataFrame, wanted: list[str], prepend: list[str] | None = None) -> pd.DataFrame:
    prepend = prepend or []
    keep = [c for c in wanted if c in df.columns]
    rest = [c for c in df.columns if c not in (set(prepend) | set(keep))]
    return df[[*(c for c in prepend if c in df.columns), *keep, *rest]]

def coerce_datetimes(df: pd.DataFrame, cols: list[str]) -> pd.DataFrame:
    for c in cols:
        if c in df.columns:
            df[c] = pd.to_datetime(df[c], errors="coerce", utc=False)
            try:
                if getattr(df[c].dt, "tz", None) is not None:
                    df[c] = df[c].dt.tz_localize(None)
            except Exception:
                pass
    return df



def build_datetime_column_config(df: pd.DataFrame, cols: list[str]) -> dict:
    cfg = {}
    for c in cols:
        if c not in df.columns:
            continue
        if pd.api.types.is_datetime64_any_dtype(df[c]):
            cfg[c] = st.column_config.DatetimeColumn(format="DD/MM/YYYY HH:mm", disabled=True)
        else:
            cfg[c] = st.column_config.TextColumn(disabled=True)
    return cfg


def sql_str(v):
    if v is None or (isinstance(v, float) and pd.isna(v)): 
        return "NULL"
    s = str(v).replace("'", "''")
    return f"'{s}'"


def _sql_escape(val):
    import pandas as pd
    if val is None or (isinstance(val, float) and pd.isna(val)):
        return "NULL"
    if isinstance(val, (int, float)):
        return str(val)
    return "'" + str(val).replace("'", "''") + "'"

def _build_desc(row_after) -> str:
    """
    Recria DESCRICAO a partir de ESPECIFICACAO, seguindo 5_Atualizacao.
    - Se DESCRICAO est√° vazio/nulo, tenta extrair de ESPECIFICACAO
    """
    desc = row_after.get("DESCRICAO")
    if (desc is None or str(desc).strip() == "") and "ESPECIFICACAO" in row_after:
        return extrair_valores(row_after.get("ESPECIFICACAO", "") or "")
    return desc if desc is not None else ""

def _build_sinonimo_like_update(row_after) -> str:
    """
    Recalcula SINONIMO com a MESMA assinatura usada na 5_Atualizacao.
    """
    desc = _build_desc(row_after)
    return gerar_sinonimo(
        row_after.get("ITEM"),
        desc or row_after.get("DESCRICAO") or "",
        row_after.get("MARCA"),
        row_after.get("QTD_MED"),
        row_after.get("UN_MED"),
        row_after.get("EMB_PRODUTO"),
        row_after.get("QTD_EMB_COMERCIAL"),
        row_after.get("EMB_COMERCIAL"),
    )

def _recalc_sinonimo_df_inplace(df: pd.DataFrame) -> pd.DataFrame:
    """
    Recalcula DESCRICAO (se vazia) e SINONIMO para TODAS as linhas vis√≠veis no DataFrame.
    Retorna o pr√≥prio df (mutado) para encadear.
    """
    if "SINONIMO" not in df.columns:
        df["SINONIMO"] = ""
    if "DESCRICAO" not in df.columns:
        df["DESCRICAO"] = ""

    def _calc(row):
        # monta um dict estilo "row_after" (igual 5_Atualizacao)
        row_after = row.to_dict()
        novo_desc = _build_desc(row_after)
        row_after["DESCRICAO"] = novo_desc
        return novo_desc, _build_sinonimo_like_update(row_after)

    out = df.apply(lambda r: pd.Series(_calc(r), index=["__DESC_NEW__", "__SIN_NEW__"]), axis=1)
    # aplica descri√ß√£o nova apenas se a atual estiver vazia/nula (mesmo crit√©rio do helper)
    mask_apply_desc = df["DESCRICAO"].astype(str).str.strip().eq("") | df["DESCRICAO"].isna()
    df.loc[mask_apply_desc, "DESCRICAO"] = out["__DESC_NEW__"]
    df["SINONIMO"] = out["__SIN_NEW__"]
    return df

def _persist_sinonimo_batch(session, table_fqn: str, df_ids: pd.DataFrame, id_col: str = "ID"):
    """
    Atualiza no banco em lote:
      - Atualiza DESCRICAO (apenas quando calculada nova)
      - Atualiza SINONIMO (sempre com o valor recalculado)
    Usa CASE ... WHEN ... THEN ... para efici√™ncia.
    """
    import pandas as pd
    if df_ids.empty or id_col not in df_ids or "SINONIMO" not in df_ids:
        return

    # Garantir colunas
    work = df_ids[[id_col, "SINONIMO"]].copy()
    has_desc = "DESCRICAO" in df_ids.columns
    if has_desc:
        work["__DESC_APPLY__"] = df_ids["DESCRICAO"]
    # prepara pares
    pairs = []
    for _, r in work.iterrows():
        _id = int(r[id_col])
        _sin = "" if pd.isna(r["SINONIMO"]) else str(r["SINONIMO"])
        _desc = None
        if has_desc:
            _desc = None if pd.isna(r["__DESC_APPLY__"]) else str(r["__DESC_APPLY__"])
        pairs.append((_id, _sin, _desc))

    if not pairs:
        return

    ids_csv = ", ".join(str(i) for (i, _, __) in pairs)
    when_sin = " ".join([f"WHEN {i} THEN {_sql_escape(s)}" for (i, s, __) in pairs])

    sets = [f"SINONIMO = CASE {id_col} {when_sin} END"]
    if has_desc:
        # Atualiza DESCRICAO somente quando veio calculada (evitar sobrepor se usu√°rio alterou manualmente)
        when_desc = " ".join([f"WHEN {i} THEN {_sql_escape(d) if d is not None else 'DESCRICAO'}"
                              for (i, _, d) in pairs])
        sets.append(f"DESCRICAO = CASE {id_col} {when_desc} END")

    sql = f"""
        UPDATE {table_fqn}
        SET {", ".join(sets)}
        WHERE {id_col} IN ({ids_csv})
    """
    session.sql(sql).collect()


##### Filtros
ALL_LABEL = "Todos"
NULL_LABEL = "(vazio)"
def norm_str_series(s: pd.Series, *, drop_dot_zero: bool = False) -> pd.Series:
    """
    Normaliza valores para filtros:
    - converte para string
    - remove .0 no final (√∫til p/ EAN vindo como float)
    - strip
    - vazio -> NA
    """
    s = s.astype("string")
    if drop_dot_zero:
        s = s.str.replace(r"\.0$", "", regex=True)
    s = s.str.strip()
    s = s.replace(["", "nan", "NaN", "None"], pd.NA)
    return s

def dropdown_options(s_norm: pd.Series, *, all_label: str = ALL_LABEL, null_label: str = NULL_LABEL) -> list[str]:
    opts = [all_label]
    if s_norm.isna().any():
        opts.append(null_label)

    uniq = pd.Series(pd.unique(s_norm.dropna())).astype("string")
    uniq = uniq[uniq.str.len() > 0].sort_values()
    opts.extend(uniq.tolist())
    return opts

def apply_dropdown_to_mask(
    mask: pd.Series,
    s_norm: pd.Series,
    selected: str,
    *,
    all_label: str = ALL_LABEL,
    null_label: str = NULL_LABEL
) -> pd.Series:
    if selected == all_label:
        return mask
    if selected == null_label:
        return mask & s_norm.isna()
    return mask & (s_norm == selected)


def resend_to_validacao(session, edited_df: pd.DataFrame, ids: list[int], user: dict):
    """
    Atualiza campos edit√°veis em FQN_COR, move de FQN_COR -> FQN_MAIN (fila de valida√ß√£o),
    zera campos de valida√ß√£o em MAIN, audita e remove de FQN_COR.
    """
    if not ids:
        return

    session.sql("ALTER SESSION SET TIMEZONE = 'America/Sao_Paulo'").collect()

    # mapa id -> linha editada (somente ids selecionados)
    edited_map = {int(r["ID"]): r for _, r in edited_df.iterrows() if int(r["ID"]) in ids}

    cols_cor   = [c.name for c in session.table(FQN_COR).schema]
    cols_main  = [c.name for c in session.table(FQN_MAIN).schema]
    common_cols = [c for c in cols_cor if c in cols_main]
    col_list = ", ".join(common_cols)

    # Auditoria: marcar a√ß√£o de reenvio para valida√ß√£o
    values_audit = []
    for _id in ids:
        row = edited_map[_id]
        cod = None if pd.isna(row.get("CODIGO_PRODUTO")) else str(row.get("CODIGO_PRODUTO"))
        values_audit.append(
            f"({_id}, {sql_str(cod)}, 'REENVIADO_VALIDACAO', {sql_str('Reenviado para valida√ß√£o ap√≥s corre√ß√£o')}, {sql_str(user['username'])}, {sql_str(user['name'])})"
        )

    ids_csv = ", ".join(str(i) for i in ids)

    try:
        session.sql("BEGIN").collect()

        # 1) UPDATE nos campos edit√°veis em COR + carimbar DATA_ATUALIZACAO
        for _id in ids:
            row = edited_map[_id]
            sets = []
            for c in EDITABLE_COR_COLS:
                if c in row:
                    sets.append(f"{c} = {sql_str(row[c])}")
            if sets:
                sql_upd = f"""
                    UPDATE {FQN_COR}
                    SET {', '.join(sets)}, DATA_ATUALIZACAO = CURRENT_TIMESTAMP()
                    WHERE ID = {_id}
                """
                session.sql(sql_upd).collect()

        # 2) Inserir de COR -> MAIN (fila de valida√ß√£o)
        sql_insert = f"""
            INSERT INTO {FQN_MAIN} ({col_list})
            SELECT {col_list}
            FROM {FQN_COR}
            WHERE ID IN ({ids_csv})
        """
        session.sql(sql_insert).collect()

        # 3) Zerar campos de valida√ß√£o e atualizar metadados em MAIN
        # (se as colunas existirem)
        cols_main_all = set(cols_main)
        meta_sets = []

        if "DATA_ATUALIZACAO" in cols_main_all:
            meta_sets.append("DATA_ATUALIZACAO = NULL")
        if "USUARIO_ATUALIZACAO" in cols_main_all:
            meta_sets.append("USUARIO_ATUALIZACAO = NULL")
        
        if meta_sets:
            # usamos os mesmos IDs rec√©m inseridos; como a PK √© ID e foi copiada, funciona 1:1
            session.sql(f"""
                UPDATE {FQN_MAIN}
                SET {', '.join(meta_sets)}
                WHERE ID IN ({ids_csv})
            """).collect()


        # 5) Remover do COR
        session.sql(f"DELETE FROM {FQN_COR} WHERE ID IN ({ids_csv})").collect()

        session.sql("COMMIT").collect()
        st.toast(f"{len(ids)} item(ns) reenviado(s) para Valida√ß√£o.", icon="üì§")
    except Exception as e:
        session.sql("ROLLBACK").collect()
        st.error(f"Falha ao reenviar para valida√ß√£o: {e}")

try:        
        df_cor = session.sql(f"""
            SELECT * EXCLUDE (DATA_ATUALIZACAO, USUARIO_ATUALIZACAO)
            FROM {FQN_COR}
        """).to_pandas()

        if "REPROVADO_EM" in df_cor.columns:
            df_cor = df_cor.sort_values("REPROVADO_EM", ascending=False)
except Exception as e:
        st.error(f"Erro ao carregar corre√ß√µes: {e}")
        df_cor = pd.DataFrame()

if df_cor.empty:
        st.info("Nenhum item reprovado.")
else:
        user_map = load_user_display_map(session)

        st.subheader("Filtros")
        ######
        s_insumo = norm_str_series(df_cor["INSUMO"]) if "INSUMO" in df_cor.columns else pd.Series(pd.NA, index=df_cor.index, dtype="string")
        s_codigo = norm_str_series(df_cor["CODIGO_PRODUTO"], drop_dot_zero=True) if "CODIGO_PRODUTO" in df_cor.columns else pd.Series(pd.NA, index=df_cor.index, dtype="string")

        s_grupo = norm_str_series(df_cor["GRUPO"]) if "GRUPO" in df_cor.columns else pd.Series(pd.NA, index=df_cor.index, dtype="string")
        s_categoria = norm_str_series(df_cor["CATEGORIA"]) if "CATEGORIA" in df_cor.columns else pd.Series(pd.NA, index=df_cor.index, dtype="string")
        s_segmento = norm_str_series(df_cor["SEGMENTO"]) if "SEGMENTO" in df_cor.columns else pd.Series(pd.NA, index=df_cor.index, dtype="string")
        s_familia = norm_str_series(df_cor["FAMILIA"]) if "FAMILIA" in df_cor.columns else pd.Series(pd.NA, index=df_cor.index, dtype="string")
        s_subfamilia = norm_str_series(df_cor["SUBFAMILIA"]) if "SUBFAMILIA" in df_cor.columns else pd.Series(pd.NA, index=df_cor.index, dtype="string")

        # Op√ß√µes
        opt_insumo = dropdown_options(s_insumo)
        opt_codigo = dropdown_options(s_codigo)

        opt_grupo = dropdown_options(s_grupo)
        opt_categoria = dropdown_options(s_categoria)
        opt_segmento = dropdown_options(s_segmento)
        opt_familia = dropdown_options(s_familia)
        opt_subfamilia = dropdown_options(s_subfamilia)

        # Linha 1 (4 colunas)
        c1, c2, c3, c4 = st.columns(4)
        with c1:
            sel_user = st.selectbox(
                "Usu√°rio (cadastro)",
                build_user_options(df_cor, user_map),
                index=0,
                key="cat_sel_user"
            )
        with c2:
            sel_insumo = st.selectbox(
                "Insumo",
                opt_insumo,
                index=0,
                key="cat_sel_insumo_dd"
            )
        with c3:
            sel_codigo = st.selectbox(
                "C√≥digo do Produto (exato)",
                opt_codigo,
                index=0,
                key="cat_sel_codigo_dd"
            )
        with c4:
            f_palavra = st.text_input("Palavra-chave (cont√©m)", key="cat_f_palavra")

        # Linha 2 (4 colunas)
        d1, d2, d3, d4 = st.columns(4)
        with d1:
            sel_grupo = st.selectbox("Grupo", opt_grupo, index=0, key="cat_sel_grupo_dd")
        with d2:
            sel_categoria = st.selectbox("Categoria", opt_categoria, index=0, key="cat_sel_categoria_dd")
        with d3:
            sel_segmento = st.selectbox("Segmento", opt_segmento, index=0, key="cat_sel_segmento_dd")
        with d4:
            sel_familia = st.selectbox("Fam√≠lia", opt_familia, index=0, key="cat_sel_familia_dd")

        # Linha 3 (Subfam√≠lia)
        e1, e2, e3, e4 = st.columns(4)
        with e1:
            sel_subfamilia = st.selectbox("Subfam√≠lia", opt_subfamilia, index=0, key="cat_sel_subfamilia_dd")

        mask = apply_common_filters(
            df_cor,
            sel_user_name=sel_user,
            f_insumo="",  
            f_codigo="",   
            f_palavra=f_palavra,  # mant√©m
            user_map=user_map,
        )

        # Aplica filtros dropdown (exatos)
        mask = apply_dropdown_to_mask(mask, s_insumo, sel_insumo)
        mask = apply_dropdown_to_mask(mask, s_codigo, sel_codigo)

        mask = apply_dropdown_to_mask(mask, s_grupo, sel_grupo)
        mask = apply_dropdown_to_mask(mask, s_categoria, sel_categoria)
        mask = apply_dropdown_to_mask(mask, s_segmento, sel_segmento)
        mask = apply_dropdown_to_mask(mask, s_familia, sel_familia)
        mask = apply_dropdown_to_mask(mask, s_subfamilia, sel_subfamilia)

        
        #####

        df_cor_view = df_cor[mask].copy()



        if df_cor_view.empty:
            st.info("Nenhum item com os filtros aplicados.")
        else:
            if "Selecionar" not in df_cor_view.columns:
                df_cor_view.insert(0, "Selecionar", False)
                
            cnt = session.sql(f"SELECT COUNT(*) AS N FROM {FQN_COR}").collect()[0]["N"]
            st.caption(f"Total reprovados no banco: **{cnt}**")
            
            left_sel_cor, right_sel_cor = st.columns([1, 3])
            with left_sel_cor:
                select_all_cor = st.checkbox("Selecionar todos", key="cor_select_all")
            if select_all_cor:
                df_cor_view["Selecionar"] = True
            
            if st.button("Recarregar tabela"):
                st.rerun()

            df_cor_view = _recalc_sinonimo_df_inplace(df_cor_view)
            # (Opcional) persistir j√° em COR para refletir na base
            try:
                _persist_sinonimo_batch(session, FQN_COR, df_cor_view[["ID","DESCRICAO","SINONIMO"]])
            except Exception as e:
                st.warning(f"N√£o foi poss√≠vel atualizar SINONIMO/descri√ß√£o (corre√ß√µes): {e}")

            DT_COLS_COR = ["DATA_REPROVACAO", "DATA_CADASTRO"]
            df_cor_view = coerce_datetimes(df_cor_view, DT_COLS_COR)
            dt_cfg_cor  = build_datetime_column_config(df_cor_view, DT_COLS_COR)
            df_cor_view = reorder(df_cor_view, ORDER_CORRECOES, prepend=["Selecionar"])
            LOCK_COR = {"ID","DATA_CADASTRO","USUARIO_CADASTRO","DATA_REPROVACAO","USUARIO_REPROVACAO","MOTIVO"}

            col_cfg_cor = {}
            for c in df_cor_view.columns:
                if c == "Selecionar":
                    col_cfg_cor[c] = st.column_config.CheckboxColumn(label="Selecionar")
                elif c in dt_cfg_cor:
                    col_cfg_cor[c] = dt_cfg_cor[c]  # j√° vem com disabled=True do helper
                elif c in LOCK_COR:
                    col_cfg_cor[c] = st.column_config.Column(disabled=True)
                else:
                    pass
            edited_cor = st.data_editor(
                df_cor_view,
                num_rows="fixed",
                hide_index=True,
                width="stretch",
                key="editor_correcao_page",
                column_config=col_cfg_cor,
            )

            sel_mask = edited_cor["Selecionar"] if "Selecionar" in edited_cor.columns else pd.Series(False, index=edited_cor.index)
            sel_ids  = edited_cor.loc[sel_mask == True, "ID"].tolist() if "ID" in edited_cor.columns else []

            st.markdown("---")
            left, right = st.columns([2,1])
            with left:
                st.caption("Atualize os valores necess√°rios diretamente na tabela acima, selecione as linhas e aprove.")
            with right:
                if st.button("‚úÖ Aprovar selecionados", disabled=(len(sel_ids) == 0), key="cor_btn_aprovar"):
                    try:
                        sel_df = edited_cor[edited_cor["ID"].isin(sel_ids)].copy()
                        sel_df = _recalc_sinonimo_df_inplace(sel_df)
                        _persist_sinonimo_batch(session, FQN_COR, sel_df[["ID","DESCRICAO","SINONIMO"]])
                    except Exception as e:
                        st.warning(f"Falha ao sincronizar SINONIMO antes do reenvio: {e}")
                    # <<< FIM >>>
                    resend_to_validacao(session, edited_cor, sel_ids, user)
                    st.rerun()
